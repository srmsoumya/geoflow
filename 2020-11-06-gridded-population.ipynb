{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Part 1: GeoFLOW - How to create effective GeoSpatial workflow using Python & Jupyter Notebook\"\n",
    "> \"GeoSpatial Data Analysis has a visual component to it. As a Data Scientist, you would prefer to look at the intermediary steps in the processing pipeline. This has a two fold impact, first, it provides a better intutition about your data & second, makes bug trackking easier. Let us try to understand this better, by solving a mystery, Where do people tend to live?\"\n",
    "\n",
    "- toc: false\n",
    "- branch: master\n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [GIS]\n",
    "- image: images/geoflow-banner-1.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"google.com\" role=\"button\" target=\"_blank\"><img class=\"notebook-badge-image\" src=\"{{ \"assets/badges/github.svg\" | relative_url }}\" alt=\"View On GitHub\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Where do people live?\n",
    "\n",
    "Population data is available at a low spatial & temporal resolution. For most of the countries around the world, it is done once every 10 years & available at a ward level at best.\n",
    "\n",
    "Goverment, NGOs & other public bodies design a lot of policy & measures based on this outdated data. In the event of an endemic or natural disaster, it would help a lot if you know exactly where people live & track their movements.\n",
    "\n",
    "To address this issue, we will try to estimate the human population at 100m x 100m GRID level. Using Building footprints as proxy for human settlement, we will see how to distribute a global datasource like Gridded Population of the World (GPW) can be used to estimate the human population at such granular resolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Details of the city under consideration\n",
    "\n",
    "We are looking at the city of [Fortportal, which is regarded as the tourism city in Uganda](https://en.wikipedia.org/wiki/Fort_Portal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "ExecuteTime": {
     "end_time": "2020-08-21T15:34:57.416967Z",
     "start_time": "2020-08-21T15:34:57.410872Z"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "REGION = 'fortportal'\n",
    "UTM = 32636\n",
    "PIPELINE = 'output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "ExecuteTime": {
     "end_time": "2020-08-21T15:34:58.892158Z",
     "start_time": "2020-08-21T15:34:58.047938Z"
    }
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio as rio\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from datetime import datetime as dt\n",
    "from pathlib import Path\n",
    "from rasterio.mask import mask\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "WGS84 = 4326\n",
    "MERCATOR = 3857\n",
    "CWD = Path('.')\n",
    "DATA = Path('data')\n",
    "\n",
    "INTER  = DATA/'inter'\n",
    "INPUT  = DATA/'input'\n",
    "OUTPUT = DATA/'output'\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "def show(*args):\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 10))\n",
    "    ax.set_axis_off()\n",
    "    \n",
    "    for d in args:\n",
    "        if type(d) is gpd.GeoDataFrame:\n",
    "            d.plot(ax=ax, facecolor='olive', edgecolor='white', alpha=0.5)\n",
    "        elif type(d) is np.ndarray:\n",
    "            ax.imshow(d, cmap='RdYlGn_r', extent=box[[0,2,1,3]])\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Load the city boundary GeoJSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "ExecuteTime": {
     "end_time": "2020-08-21T15:35:03.288313Z",
     "start_time": "2020-08-21T15:35:03.256805Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Read the data & change the CRS to 4326\n",
    "region = gpd.read_file(INPUT/f'{REGION}.geojson').to_crs(epsg=WGS84)\n",
    "box    = region.total_bounds\n",
    "\n",
    "show(region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Load Population data\n",
    "\n",
    "- Read the [Gridded Population of the World (GPW)](https://sedac.ciesin.columbia.edu/data/collection/gpw-v4) dataset, which is available as a Raster TIFF file\n",
    "- Clip it to the city boundary using the GeoJSON file\n",
    "- Save the clipped raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "ExecuteTime": {
     "end_time": "2020-08-21T15:35:15.355647Z",
     "start_time": "2020-08-21T15:35:15.045684Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Read GPW data\n",
    "gpw = rio.open(INPUT/'gpw_world.tif')\n",
    "gpw_region = gpw.read(1, window=gpw.window(*box))\n",
    "\n",
    "# Clip to the region boundary\n",
    "region_mask, region_mask_tfm = mask(dataset=gpw, shapes=region.geometry, all_touched=True, crop=True, filled=True)\n",
    "region_mask = np.where(region_mask < 0, 0, region_mask).squeeze()\n",
    "\n",
    "# Save the clipped raster\n",
    "region_meta = gpw.meta\n",
    "region_meta.update(dict(\n",
    "    driver='GTiff',\n",
    "    height=region_mask.shape[0],\n",
    "    width=region_mask.shape[1],\n",
    "    transform=region_mask_tfm\n",
    "))\n",
    "with rio.open(INTER/f'{REGION}_gpw_output.tif', 'w', **region_meta) as f: f.write(region_mask, indexes=1)\n",
    "\n",
    "show(region, region_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Polygonize the clipped raster\n",
    "\n",
    "Population data for the city is now available as a Raster TIFF file. In order to read it as a GeoDataFrame & perform spatial operations, we would need to polygonise the raster into a vector format.\n",
    "\n",
    "We can do this using the rasterio library in python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-06T10:27:02.980743Z",
     "iopub.status.busy": "2020-11-06T10:27:02.980552Z",
     "iopub.status.idle": "2020-11-06T10:27:02.984331Z",
     "shell.execute_reply": "2020-11-06T10:27:02.983611Z",
     "shell.execute_reply.started": "2020-11-06T10:27:02.980725Z"
    }
   },
   "source": [
    "> Tip: Use rasterio CLI inside jupyter notebooks, save a few lines of pythonic code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "ExecuteTime": {
     "end_time": "2020-08-21T15:35:19.508913Z",
     "start_time": "2020-08-21T15:35:18.371680Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Converts vector to raster\n",
    "!rio shapes {INTER/REGION}_gpw_output.tif --bidx 1 --precision 6 > {INTER/REGION}_gpw_output.geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide_input\n",
    "# Clean vectorized GPW data & add tile_width, tile_height as properties\n",
    "\n",
    "from functools import wraps\n",
    "from datetime import datetime as dt\n",
    "\n",
    "\n",
    "def log(fn):\n",
    "    @wraps(fn)\n",
    "    def _inner(*args, **kwargs):\n",
    "        tic = dt.now()\n",
    "        r = fn(*args, **kwargs)\n",
    "        tac = dt.now()\n",
    "        # print(f'Shape: {r.shape}, Execution time: {((tac - tic).microseconds)/1000:.2f} ms, Function: {fn.__name__}')\n",
    "        return r\n",
    "    return _inner\n",
    "\n",
    "@log\n",
    "def make_copy(df): return df.copy()\n",
    "\n",
    "@log\n",
    "def drop_cols(df, labels=None): return df.drop(labels, axis=1)\n",
    "\n",
    "@log\n",
    "def filter_rows(df, cond): return df.query(cond)\n",
    "\n",
    "@log\n",
    "def change_crs(df, crs): return df.to_crs(epsg=crs)\n",
    "\n",
    "@log\n",
    "def add_attrs(df):\n",
    "    bounds = df.geometry.bounds\n",
    "    width  = bounds['maxx'] - bounds['minx']\n",
    "    height = bounds['maxy'] - bounds['miny']\n",
    "    \n",
    "    min_width  = np.min(width)\n",
    "    min_height = np.min(height)\n",
    "    \n",
    "    df['width']  = ((bounds['maxx'] - bounds['minx']) / min_width ).astype(int)\n",
    "    df['height'] = ((bounds['maxy'] - bounds['miny']) / min_height).astype(int)\n",
    "    \n",
    "    df = df.reset_index(drop=True).reset_index()\n",
    "    df = df.rename(columns={'index': 'tile_idx', 'val': 'tile_population', 'width': 'tile_width', 'height': 'tile_height'})\n",
    "    \n",
    "    return df\n",
    "\n",
    "tiles_gdf = gpd.read_file(f'{INTER/REGION}_gpw_output.geojson')\n",
    "\n",
    "tiles_gdf = (tiles_gdf.pipe(make_copy)\n",
    "            .pipe(drop_cols, labels=['id', 'filename'])\n",
    "            .pipe(filter_rows, 'val > 0')\n",
    "            .pipe(change_crs, MERCATOR)\n",
    "            .pipe(add_attrs))\n",
    "\n",
    "display(tiles_gdf.head())\n",
    "\n",
    "# BUG in rasterio: Combines adjacent tiles but doesn't aggregate the values\n",
    "tiles_gdf['tile_population'] = tiles_gdf['tile_population'] * (tiles_gdf.tile_width * tiles_gdf.tile_height)\n",
    "\n",
    "# The area printed is not correct, as the projection is MERCATOR\n",
    "print(f'# of tiles: {tiles_gdf.shape[0]}, Area covered: {tiles_gdf.area.sum() / 1000000:.2f} km.sq')\n",
    "\n",
    "print(f'''Population statistics: mean: {tiles_gdf.tile_population.mean():.2f}, median: {tiles_gdf.tile_population.median():.2f}, std: {tiles_gdf.tile_population.std():.2f}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Gridify\n",
    "\n",
    "The vectorized GPW GeoJSON file gives us **population** for the city at **1km x 1km spatial resolution**.\n",
    "\n",
    "The intent is to estimate the population at **100m x 100m spatial resolution**. To achieve this, we have to:\n",
    "- Gridify: Split the 1km x 1km TILE into smaller grids of size 100m x 100m\n",
    "- Each 1km x 1km TILE will give us 100 GRIDs of size 100m x 100m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Tip: Gridification works well only for the MERCATOR projection, make sure your GeoDataFrames have proper CRS before performing this operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "ExecuteTime": {
     "end_time": "2020-08-21T15:35:37.821053Z",
     "start_time": "2020-08-21T15:35:30.278801Z"
    }
   },
   "outputs": [],
   "source": [
    "def gridify(tile):\n",
    "    polygons = []\n",
    "    xmin,ymin,xmax,ymax = tile.geometry.bounds\n",
    "    width = tile.tile_width\n",
    "    height = tile.tile_height\n",
    "\n",
    "    stepx = +(xmax - xmin)/(10 * width )\n",
    "    stepy = -(ymax - ymin)/(10 * height)\n",
    "\n",
    "    for x in np.arange(xmin, xmax, stepx):\n",
    "        for y in np.arange(ymax, ymin, stepy):\n",
    "            poly = [\n",
    "                (x        , y        ),\n",
    "                (x + stepx, y        ),\n",
    "                (x + stepx, y + stepy),\n",
    "                (x        , y + stepy)\n",
    "            ]\n",
    "            polygons.append(Polygon(poly))\n",
    "\n",
    "    d = {\n",
    "        'geometry': polygons,\n",
    "        'tile_idx': tile.tile_idx,\n",
    "        'tile_population': tile.tile_population,\n",
    "        'tile_width': tile.tile_width,\n",
    "        'tile_height': tile.tile_height\n",
    "    }\n",
    "    \n",
    "    grids_gdf = gpd.GeoDataFrame(d, crs=f'EPSG:{MERCATOR}')\n",
    "    tile_gdf  = gpd.GeoDataFrame(tile.to_frame().T, crs=f'EPSG:{MERCATOR}')\n",
    "    grids_gdf = gpd.clip(grids_gdf, tile_gdf)\n",
    "        \n",
    "    return grids_gdf\n",
    "\n",
    "# For each TILE create the GRIDs\n",
    "grids_gdf = tiles_gdf.apply(gridify, axis=1)\n",
    "grids_gdf = pd.concat(grids_gdf.to_list())\n",
    "grids_gdf = grids_gdf.reset_index(drop=True).reset_index().rename(columns={'index': 'idx'}).to_crs(epsg=UTM)\n",
    "\n",
    "# Change the CRS of TILEs & GRIDs back to their region respective UTM coordinates\n",
    "tiles_gdf = tiles_gdf.to_crs(epsg=UTM)\n",
    "grids_gdf = grids_gdf.to_crs(epsg=UTM)\n",
    "region = region.to_crs(epsg=UTM)\n",
    "\n",
    "grids_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide_input\n",
    "# Plot the 100m x 100m GRIDs for each TILE\n",
    "fig, ax = plt.subplots(1,1,figsize=(10, 10))\n",
    "grids_gdf.plot(ax=ax, cmap='RdYlGn_r', edgecolor='k', alpha=0.5, column='tile_population')\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Load building footprints dataset\n",
    "\n",
    "We are using buildings as a proxy for estimating the human population.\n",
    "\n",
    "Microsoft has been kind of to release building footprints for multiple regions around the globe, please check them out [HERE](https://www.microsoft.com/en-us/maps/building-footprints). Fortunately, the city we are considering here (Fortportal in Uganda) is also made available by them.\n",
    "\n",
    "If you are considering a region for which there are no readily available building footprints, here are a few alternatives:\n",
    "- Check Open Street Map (OSM), they have a good coverage of a lot of places around the globe. Also, consider contributing to that as well\n",
    "- Put your deep learning skills in practice, try getting hands on some satellite imagery of the region & generate building footprints using Segmentation models. Dave luo has a nice blog post about the same [LINK](https://medium.com/@anthropoco/how-to-segment-buildings-on-drone-imagery-with-fast-ai-cloud-native-geodata-tools-ae249612c321)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "ExecuteTime": {
     "end_time": "2020-08-21T15:35:51.686257Z",
     "start_time": "2020-08-21T15:35:45.658463Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Read the building footprints data, compute the centroid & area occupied by each building\n",
    "footprints_gdf = (gpd.read_file(f'{INPUT/REGION}_footprints.geojson')\n",
    "                     .to_crs(epsg=UTM)\n",
    "                     .assign(centroid=lambda x: x.centroid,\n",
    "                             building_area=lambda x:x.geometry.area)\n",
    "                     .rename(columns={'geometry': 'building_count'})\n",
    "                     .set_geometry('centroid'))\n",
    "\n",
    "footprints_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide_input\n",
    "fig, ax = plt.subplots(1,1,figsize=(10, 10))\n",
    "grids_gdf.plot(ax=ax, cmap='RdYlGn_r', edgecolor='black', alpha=0.5, column='tile_population')\n",
    "footprints_gdf.plot(ax=ax, color='black', alpha=0.5, markersize=2)\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute building statistics (# of buildings, area occupied by buildings) for each GRID\n",
    "\n",
    "Now, we have:\n",
    "- GRIDs at 100m x 100m resolution\n",
    "- Building footprints for the city\n",
    "\n",
    "We would like to find the buildings falling under each GRID & then compute their count & area occupancy. We can do a spatial join between the two DataFrames, which is much faster thanks to geopandas > 0.8. We take the centroid of each building footprints & do a spatial join with the GRID boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "ExecuteTime": {
     "end_time": "2020-08-21T15:36:27.735481Z",
     "start_time": "2020-08-21T15:36:22.561616Z"
    }
   },
   "outputs": [],
   "source": [
    "def sjoin_polygon_footprints(poly_gdf, footprints_gdf, idx, name, agg):\n",
    "    poly_gdf = gpd.sjoin(poly_gdf, footprints_gdf, how='left', op='intersects')\n",
    "    poly_gdf = (poly_gdf.groupby(idx)\n",
    "                        .agg(agg)\n",
    "                        .reset_index())\n",
    "    \n",
    "    poly_gdf = (gpd.GeoDataFrame(poly_gdf, crs=f'EPSG:{UTM}')\n",
    "              .rename(columns={'building_area' : f'{name}_building_area', \n",
    "                               'building_count': f'{name}_building_count'}))\n",
    "    \n",
    "    return poly_gdf\n",
    "\n",
    "agg = {\n",
    "    'geometry'           : 'first',\n",
    "    'building_area'      : 'sum',\n",
    "    'building_count'     : 'count',\n",
    "    'tile_idx'           : 'first',\n",
    "    'tile_population'    : 'first',\n",
    "    'tile_width'         : 'first',\n",
    "    'tile_height'        : 'first'\n",
    "}\n",
    "\n",
    "grids_gdf = sjoin_polygon_footprints(grids_gdf, footprints_gdf, 'idx', 'grid', agg=agg)\n",
    "grids_gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove extra GRIDs that fall beyond the region boundary & adjust the population accordingly\n",
    "\n",
    "The GPW population data is available to us at 1km x 1km resolution, we are clipping that to the region boundary. When we split the TILE into GRIDs, along the edges there will be GRIDs that fall beyond the region boundary. However, we will not have building footprints available for areas outside our region boundary, so we remove the extra grids & adjust the population count by taking a ratio of the # of grids that fall with in the region boundary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "ExecuteTime": {
     "end_time": "2020-08-21T15:36:40.017023Z",
     "start_time": "2020-08-21T15:36:35.906978Z"
    }
   },
   "outputs": [],
   "source": [
    "#hide_input\n",
    "show(region, grids_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "ExecuteTime": {
     "end_time": "2020-08-21T15:36:52.199574Z",
     "start_time": "2020-08-21T15:36:48.652958Z"
    }
   },
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "grids_gdf = gpd.sjoin(grids_gdf, region[['geometry']], how='inner', op='intersects').drop(labels='index_right', axis=1)\n",
    "\n",
    "# Fix the index of the grids\n",
    "grids_gdf = (grids_gdf.drop(labels='idx', axis=1)\n",
    "                      .reset_index(drop=True).reset_index()\n",
    "                      .rename(columns={'index': 'idx'}))\n",
    "\n",
    "# Adjust the population accordingly\n",
    "\n",
    "def recompute_population_by_grids(gp):\n",
    "    if gp.grid_building_count.sum() <= 1:  gp.tile_population = 0\n",
    "    return gp.tile_population * (gp.shape[0] / (gp.tile_width * gp.tile_height * 100))\n",
    "\n",
    "grids_gdf['tile_population'] = (grids_gdf.groupby('tile_idx')\n",
    "                                         .apply(recompute_population_by_grids)\n",
    "                                         .values)\n",
    "\n",
    "show(region, grids_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide_input\n",
    "grids_gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the Population at 100m x 100m GRID level\n",
    "\n",
    "For each grid, we have the TILE population, # of buildings inside it's boundary & the area of building inside it's boundary.\n",
    "\n",
    "We can statistically distribute the TILE population to the GRIDs by considering the building properties inside them. Like we discussed, buildings are a good proxy for human population.\n",
    "\n",
    "```\n",
    "# Tile population distributed by the ratio of # of buildings for each grid\n",
    "grid_population_count = tile_population * (grid_building_count / tile_building_count)\n",
    "\n",
    "# Tile population distributed by the ratio of area of buildings for each grid\n",
    "grid_population_area  = tile_population * (grid_building_area  / tile_building_area )\n",
    "\n",
    "grid_population = Weighted average of the above 2 metrics\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Tip: If you would like to improve over this model, conside using DEM & DSM dataset, to find building heights & use it as a factor to distribute the population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "ExecuteTime": {
     "end_time": "2020-08-21T15:37:22.551007Z",
     "start_time": "2020-08-21T15:37:22.519531Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Aggregate to get TILE stats\n",
    "grids_gdf[['tile_building_count', 'tile_building_area']] = grids_gdf.groupby('tile_idx')[['grid_building_count', 'grid_building_area']].transform('sum')\n",
    "\n",
    "# Statistically distribute the TILE population to GRIDs\n",
    "grids_gdf['grid_population'] = (0.5 * grids_gdf['tile_population'] * (grids_gdf['grid_building_count'] / grids_gdf['tile_building_count']) + \n",
    "                                0.5 * grids_gdf['tile_population'] * (grids_gdf['grid_building_area' ] / grids_gdf['tile_building_area' ]))\n",
    "\n",
    "grids_gdf.loc[:, 'grid_population'] = grids_gdf['grid_population'].fillna(0)\n",
    "\n",
    "grids_gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Let us look how the population distribution varies at 1km & 100m resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "ExecuteTime": {
     "end_time": "2020-08-21T15:48:48.499491Z",
     "start_time": "2020-08-21T15:48:44.159310Z"
    }
   },
   "outputs": [],
   "source": [
    "#hide_input\n",
    "fig, (ax1, ax2) = plt.subplots(1,2,figsize=(20, 20))\n",
    "grids_gdf.plot(ax=ax1, cmap='RdYlGn_r', edgecolor='black', alpha=1, column='tile_population', scheme='percentiles', legend=True)\n",
    "grids_gdf.plot(ax=ax2, cmap='RdYlGn_r', edgecolor='black', alpha=1, column='grid_population', scheme='percentiles', legend=True)\n",
    "\n",
    "ax1.set_title('GPW Population')\n",
    "ax2.set_title('Population at 100m resolution')\n",
    "ax1.set_axis_off()\n",
    "ax2.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the 100m x 100m GRID DataFrame\n",
    "\n",
    "> Tip: If you need the data for futher processing, consider using the feather format available in geopandas, it speeds up the reading & writing of GeoJSON files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "ExecuteTime": {
     "end_time": "2020-08-21T15:49:30.854615Z",
     "start_time": "2020-08-21T15:49:22.186466Z"
    }
   },
   "outputs": [],
   "source": [
    "grids_gdf.to_crs(WGS84).to_file(f'{OUTPUT/REGION}_grids_output_{WGS84}.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully, this gives you a fair idea on why & how to use Notebooks to create GeoSpatial workflows.\n",
    "\n",
    "In the next post, we will see how to automate notebook execution using papermill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
